# Green-Bit-LLM

A toolkit for fine-tuning, inference, and evaluating GreenBitAI's LLMs.

## Introduction
 
This Python package uses the [Bitorch Engine](https://github.com/GreenBitAI/bitorch-engine) for efficient operations on [GreenBitAI's Low-bit Language Models (LLMs)](https://huggingface.co/GreenBitAI). 
It enables high-performance inference on both cloud-based and consumer-level GPUs, and supports full-parameter fine-tuning directly using quantized LLMs. 
Additionally, you can use our provided evaluation tools to validate the model's performance on mainstream benchmark datasets.


## Features

## Installation
To get started with this package, simply clone the repository and install the required dependencies (for Python >= 3.9):
```bash
git clone https://github.com/GreenBitAI/green-bit-llm.git
pip install -r requirements.txt
```
Alternatively you can also use the prepared conda environment configuration:
```bash
conda env create -f environment.yml
conda activate gbai_cuda_lm
```

## Usage
### Inference

TODO: link to readme file in the sub-directory

### Evaluation

TODO: link to readme file in the sub-directory

### sft

TODO: link to readme file in the sub-directory

## Requirements

- Python 3.x
- See `requirements.txt` or `environment.yml` for a complete list of dependencies

## Examples
 
```bash

```

```bash

```

## License
The original code was released under its respective license and copyrights, i.e.:

- ...
- We release our changes and additions to these files under the [Apache 2.0 License](LICENSE).

